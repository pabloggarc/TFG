\chapter{Código y entorno de desarrollo}

	Todo el código desarrollado para llevar a cabo los diferentes experimentos se puede consultar en el siguiente repositorio de GitHub a través del enlace \url{https://github.com/pabloggarc/TFG}. Este es un repositorio que se ha ido utilizando durante el desarrollo del proyecto para llevar un control de versiones del código y la memoria. El contenido se divide en varios directorios. 
	
	\begin{itemize}
		\item \textbf{Anteproyecto}: archivos relacionados con el documento del anteproyecto. 
		\item \textbf{Código}: contiene el código desarrollado para el proyecto. Todos los experimentos mostrados en la memoria suceden en los archivos \texttt{.ipynb}, que son dos notebooks de Python donde aparece el código intercalado con breves comentarios teóricos que han sido extendidos en esta memoria, uno para la parte de redes neuronales convolucionales y otro para la de transformers. Por otro lado, aparecen tres ficheros \texttt{.py}, que son tres scripts utilizados para estructurar los ficheros que forman los datasets. 
		\item \textbf{Diapositivas}: contiene todos los ficheros \LaTeX{} necesarios para generar las diapositivas que se utilizarán para la defensa del proyecto. 
		\item \textbf{Logs}: aparecen en carpetas los diferentes logs generados por TensorFlow durante el entrenamiento de los modelos. Se pueden abrir con TensorBoard para recuperar información y gráficas del entrenamiento. 
		\item \textbf{Memoria}: contiene todos los ficheros \LaTeX{} necesarios para generar esta memoria. 
		\item \textbf{Modelos}: contiene los diferentes modelos entrenados con TensorFlow, listos para poder cargarlos y hacer predicciones. 
	\end{itemize}
	
	Para poder replicar los experimentos, se recomienda replicar el entorno de desarrollo comentado en el \Cref{chapter:practica}. Para ello se debe instalar Ubuntu en su versión 22.04 LTS y LambdaStack mediante el siguiente comando de terminal. 
	\begin{center}
		\begin{BVerbatim}[tabsize = 0]
			wget -nv -O- https://lambdalabs.com/install-lambda-stack.sh | sh -
		\end{BVerbatim}
	\end{center}
	Al instalar ambos elementos se habrá instalado Python, Jupyter, drivers y librerías de NVIDIA, \gls{cuda}, etc. Es importante destacar que para la parte en la que se hace una comparativa entre \gls{cpu} y \gls{gpu}, es necesario disponer de una tarjeta gráfica NVIDIA compatible con \gls{cuda}. Para los entrenamientos, si no se detecta, se harán sobre el procesador automáticamente. \\
	
	Para la parte de transformers, se necesita una cuenta activa en Google Cloud con créditos disponibles, crear un proyecto, e instalar el \gls{cli}. Para ello, basta con ejecutar el siguiente comando de terminal e iniciar sesión. 
	\begin{center}
		\begin{BVerbatim}[tabsize = 0]
			curl https://sdk.cloud.google.com | bash
		\end{BVerbatim}
	\end{center}