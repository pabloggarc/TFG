\chapter{Estado del arte}\label{chapter:estado_arte}

	A pesar de que herramientas como ChatGPT están a la orden del día y llevan poco tiempo funcionando de cara al público, se ha mostrado en la introducción de este trabajo que los fundamentos que han hecho posible su creación, empezaron a aparecer alrededor de los años 60. Ha sido la evolución del hardware y numerosas investigaciones durante las últimas décadas, las que han hecho posibles estos resultados. \\
	
	En el campo de los problemas de clasificación, uno de los modelos más habituales eran las redes neuronales. Yann LeCun presentaba en 1995 las redes neuronales convolucionales en \cite{ea_cnn}. En este artículo las proponía como una solución al problema que presentan las redes neuronales clásicas al trabajar con datos como imágenes, pues se necesitaba que a la hora de clasificarlas, el modelo fuera invariante a transformaciones como rotaciones o ampliaciones. Un ejemplo de aplicación de este tipo de modelo se muestra en \cite{medicos_ea}, donde construyendo una \gls{cnn} desde cero y entrenándola con imágenes de pulmones, los autores son capaces de detectar enfermedades. Con el paso de los años, se han ido presentando diferentes arquitecturas que mejoran la original propuesta por LeCun. Por ejemplo, en 2014 se presenta en \cite{ea_vgg} la arquitectura de la \gls{cnn} VGG, que se colocaba en el segundo puesto en cuanto a clasificación de imágenes, superada por GoogLeNet, presentada en \cite{googlenet_ea}. Esta arquitectura introducía unos bloques llamados inception, gracias a los cuales conseguía que la red quedase en los primeros puestos de clasificación y detección en competiciones como ILSVRC. Otras arquitecturas han ido adaptándose a obtener un buen rendimiento en dispositivos con bajos recursos como dispositivos móviles, por ejemplo MobileNet, presentada en \cite{mobilenet_ea}. \\
	
	En el campo de los problemas relacionados con el procesamiento del lenguaje natural, hasta hace algunos años, los modelos por excelencia eran las \gls{rnn}. Una variante de estas, las \gls{lstm}, fueron el estado del arte en tareas de procesamiento de texto y audio \cite{ea_lstm}. En algunos artículos como \cite{ea_seq}, se demuestra cómo podían ser utilizadas para lograr la traducción de textos de inglés a francés. En la actualidad, los modelos considerados el estado del arte para tareas de \gls{nlp}, son los transformers, introducidos por investigadores de Google en el famoso artículo \textit{``Attention is all you need''} \cite{attention}, que generó un punto de inflexión en el campo del aprendizaje profundo. Estos modelos conseguían solucionar los principales problemas que presentaban las redes recurrentes, como eran el procesamiento secuencial frente al procesamiento paralelo de los transformers, o el tamaño del contexto, que en el caso de los transformers es mucho más sencillo detectar relaciones entre elementos muy alejados entre sí \cite{ea_rnn_transf}. Algunos modelos muy conocidos en la actualidad basados en transformers son \gls{bert} de Google \cite{ea_bert}, o \gls{gpt} de OpenAI \cite{ea_gpt}. En ambos artículos se comenta la arquitectura de los modelos, la manera de entrenarlos, y la evaluación de estos en diferentes tareas como la traducción de textos, o responder a preguntas sobre estos.\\ 
	
	Con la evolución y modificación en la arquitectura original de los transformers, se han conseguido aplicar a tareas diferentes, como pueden ser el procesamiento de imágenes o vídeos. En \cite{vit}, los autores que propusieron la arquitectura del transformer, mostraron cómo adaptarla para trabajar con imágenes. En diferentes artículos, autores muestran cómo con ayuda de un transformer logran resultados superiores a algunas de las \gls{cnn} consideradas estado del arte, como por ejemplo para clasificar imágenes de plantas de soja y malezas \cite{ea_vit}, o las diferentes regiones de una imagen satelital \cite{ea_vit2}. Habiendo demostrado que los transformers se podían aplicar a información representada de diferentes maneras, surge la idea de los transformers multimodales. Este tipo de modelos son capaces de representar en un espacio común, información en diferentes modalidades como texto, imágenes, vídeo, etc. Uno de los modelos considerados como referencia en este ámbito es \gls{clip} de OpenAI, presentado en \cite{clip}, donde se muestra cómo es capaz de codificar en un espacio común los conceptos representados en imágenes y texto. En el TFM \cite{ea_multimodal} se muestra un caso práctico de clasificación multimodal con \gls{clip}, en el que se utilizan de manera conjunta los textos e imágenes de noticias del periódico New York Times, para clasificarlas en diferentes categorías. Además, existen otras arquitecturas que combinan elementos de diferentes tipos de modelos como, transformers multimodales, redes neuronales convolucionales, y otros; como las presentadas en \cite{arquitectura_multimodal} y \cite{atencion_multimodal}. Mediante estas se logra la representación de diferentes modalidades en un mismo espacio para asignar imágenes y textos, y la segmentación de objetos en una imagen mediante descripciones textuales. \\
	
	En este trabajo de fin de grado se propone el estudio de manera teórica de los diferentes modelos comentados, para posteriormente aplicarlos de manera práctica a la automatización del proceso de valoración de puntos de interés de videojuegos basados en realidad aumentada. Se utilizarán diferentes arquitecturas de \gls{cnn} para la clasificación de imágenes de manera supervisada, y posteriormente se propondrá una aproximación basada en transformers multimodales para mejorar la clasificación de imágenes y mostrar la posibilidad de trabajar con textos asociados a estas, todo ello de manera no supervisada. 